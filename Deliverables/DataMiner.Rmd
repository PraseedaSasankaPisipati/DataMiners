# Data Cleaning Document
### Preface
This document is prepared by Data Miners Team for the purpose of providing background information of the data set. This document also includes the code which was executed to clean the data set.

### Target Audience
The potential users of this particular data set can be:
* Doctors
* Medicine Companies
* Health Researchers’ Groups

### Table of Contents
1. Introduction
2. Draft Research Questions
3. License
4. Metadata
5. Issues encounterd with Data Cleaning
6. Strategy for Data Cleaning
7. R script for Data Cleaning

### 1. Introduction
This data represented the percentage of expected death, observed deaths and potential death in different states in the United States. All data is collected based on five leading causes of death in metropolitan and non-metropolitan areas. Heart disease, Cancer, Unintentional injury, Chronic lower respiratory disease and Stroke are the major causes of death that patients are spending so much money for any treatment for them. The data consists of 20,5921 rows and 13 columns.

With analyzing this data and finding differences between Expected Deaths and Observed Deaths, health care can improve public health programs that support healthier behaviors to better access the health care services for the purpose of reducing the rate of potentially excess deaths.

### 2. Draft Research Questions
1. What is the ratio between observed deaths and expected deaths? In which State is the ratio found greater than one maximum number of times?
2. Which states have more observed deaths than expected deaths?
3. In which locality is it more likely that the observed deaths (metropolitan or non-metropolitan) are more in each age group?
4. In which age group are the most deaths observed and what is the leading cause?
5. In which year are the most deaths observed ?
6. In which benchmark are more deaths observed ?How does this vary over time by locality?
Note: “2010 Fixed” is a fixed benchmark based on the best performing States in 2010. 
      “2015 Fixed” is a fixed benchmark based on the best performing States in 2015.
7. What are the top 5 states with more observed deaths in each category?
8. What is the ratio between the observed deaths and the Population? What is the trend of the ratios over time?
9. What is the ratio between the expected deaths and the Population? What is the trend of the ratios over time?
10. In which years are the observed deaths less in number when compared to the previous year?
11. What are the maximum and minimum number of deaths in the same age group for a particular cause of death in each state?
12. What are the top 5 states in each category:
    a. Number of observed deaths less than Benchmark
    b. Number of observed deaths equals benchmark
    c. Number of observed deaths greater than Benchmark

## 3. License:
The License details for the Excess Deaths Data Set can be found in [License Info](https://www.cms.gov/about-cms/agency-information/aboutwebsite/privacy-policy.html)

There are no constraints on this data in regards to the license. This is public data set and can be downloaded by any individual within or outside the organization. 

## 4. Metadata
This data set was collected for the years 2005-2015
**Mortality** data for U.S. residents come from the National Vital Statistics System. Estimates based on fewer than 10 observed deaths are not shown and shaded yellow on the map.

**Underlying cause of death** is based on the International Classification of Diseases, 10th Revision (ICD-10)

Heart disease (I00-I09, I11, I13, and I20–I51)
Cancer (C00–C97)
Unintentional injury (V01–X59 and Y85–Y86)
Chronic lower respiratory disease (J40–J47)
Stroke (I60–I69)

**Locality** (nonmetropolitan vs. metropolitan) is based on the Office of Management and Budget’s 2013 county-based classification scheme.

**Benchmarks** are based on the three states with the lowest age and cause-specific mortality rates.

**Potentially excess deaths** for each state are calculated by subtracting deaths at the benchmark rates (expected deaths) from observed deaths.

Users can explore three benchmarks:

“2010 Fixed” is a fixed benchmark based on the best performing States in 2010.
“2005 Fixed” is a fixed benchmark based on the best performing States in 2005.
“Floating” is based on the best performing States in each year so change from year to year.

Page last reviewed: July 14, 2017
Page last updated: August 28, 2017
Content source: [CDC/National Center for Health Statistics](https://www.cdc.gov/nchs/)

## 5. Strategies for Data Cleaning
_Steps/Strategies for cleaning data_:
1.	Analyzed the research questions and identified the required columns for analysis of Excess Deaths data set
2.	Reviewed the format of the column values in the data set to understand which command in R will be more effective to be used for this format
3.	The summary of data was obtained using R to get an overall view of the data
4.	Performed a check for missing data and found all missing data. Replaced all missing data with “NA”
5.	Tried to figure out how can we deal missing value like deleting the observations, deleting the variable, prediction or imputation with mean/median/mode. By keen observation of the data, decision was taken to delete the observations as the incomplete data cannot be of much use for the analysis. There are enormous number of observations in the data set, where all the classifications are sufficiently represented in the data. For example, having the details of locality, age, cause of death without the metrics like Expected Deaths, Potentially Excess Deaths is of not much use for analysis
6.	Checked the format of the data set to see which kind of command is needed to use in R and executed those commands in R Studio
7.	We also found few duplicate values in the data set and deleted them using R command

## 6. Issues during Data Cleaning
Below are the issues faced during cleaning the data set
	As this was the first time, all the team members are using R for data analysis, it took us time to get familiar with R. For example, creation of block for the code to run and closing the block before running the code
	Another issue was, we had the age range as 0-59, 0-64, 0-74 and so on but with the same locality, state and year. Initially, the team felt this might be redundant data. But later, when we looked at the total population values, the numbers kept increasing for each range. So, we finally reviewed the description of the data in the CDC website and understood that the age ranges were always kept at standard minimum value ‘0’. As there is no redundancy we didn’t delete any data.
	Deciding on which method to follow for the missing data was not an easy task. It consumed a lot of time too. 


## 7. R Script for Data Cleaning
---
title: "NCHS"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


```{r}


dat<-read.csv("C:/Users/asal/Desktop/Academic/fall 2017/ISQA 8086_Data 2 Decision/Information Seeking/Info Seeking/NCHS_-_Potentially_Excess_Deaths_from_the_Five_Leading_Causes_of_Death1.csv")


#Summary of data
str(dat)
summary(dat)

# find missing values
sum(is.na(dat))

aft_mis_dat<-na.omit(dat)


sum(is.na(aft_mis_dat))
str(aft_mis_dat)

```

